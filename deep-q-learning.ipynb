{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reinforcement Learning - Deep Q-Learning for Racing Kings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "!pip install numpy\n",
    "!pip install tensorflow==2.3.0\n",
    "!pip install keras\n",
    "!pip install keras-rl2\n",
    "!pip install chess"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: numpy in ./env/lib/python3.8/site-packages (1.18.5)\n",
      "Requirement already satisfied: tensorflow==2.3.0 in ./env/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.6.3)\n",
      "Requirement already satisfied: scipy==1.4.1 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.4.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (3.17.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.12.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (2.10.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.18.5)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (2.5.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (0.13.0)\n",
      "Requirement already satisfied: wheel>=0.26 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (0.36.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.39.0)\n",
      "Requirement already satisfied: gast==0.3.3 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in ./env/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (44.0.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.33.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.0.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in ./env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./env/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n",
      "Requirement already satisfied: keras in ./env/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in ./env/lib/python3.8/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: h5py in ./env/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in ./env/lib/python3.8/site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: scipy>=0.14 in ./env/lib/python3.8/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: six in ./env/lib/python3.8/site-packages (from h5py->keras) (1.16.0)\n",
      "Requirement already satisfied: keras-rl2 in ./env/lib/python3.8/site-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow in ./env/lib/python3.8/site-packages (from keras-rl2) (2.3.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.18.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (2.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (2.10.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (0.13.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (2.5.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.39.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (0.3.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (3.17.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in ./env/lib/python3.8/site-packages (from tensorflow->keras-rl2) (0.36.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.33.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./env/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (44.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in ./env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.7.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.0.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.8)\n",
      "Requirement already satisfied: chess in ./env/lib/python3.8/site-packages (1.6.1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from statistics import mean\n",
    "from racing_kings_env import RacingKingsEnvironment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial Test of the Evironment\n",
    "To ensure proper executability of the environment a few episodes of gameplay are executed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "episodes = 10\n",
    "env = RacingKingsEnvironment()\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render(mode=None)\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{} Info:{}'.format(episode, score, info))\n",
    "env.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episode:1 Score:0 Info:{'msg': 'Action is not a valid move'}\n",
      "Episode:2 Score:0 Info:{'msg': 'Action is not a valid move'}\n",
      "Episode:3 Score:0 Info:{'msg': 'Action is not a valid move'}\n",
      "Episode:4 Score:0 Info:{'msg': 'Action is not a valid move'}\n",
      "Episode:5 Score:0 Info:{'msg': 'Action is not a valid move'}\n",
      "Episode:6 Score:0 Info:{'msg': 'Action is not a valid move'}\n",
      "Episode:7 Score:0 Info:{'msg': 'Action is not a valid move'}\n",
      "Episode:8 Score:0 Info:{'msg': 'Action is not a valid move'}\n",
      "Episode:9 Score:0 Info:{'msg': 'Action is not a valid move'}\n",
      "Episode:10 Score:0 Info:{'msg': 'Action is not a valid move'}\n",
      "closing\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the Convolutional Neural Network (CNN)\n",
    "For better compatibility with the task of Racing Kings a Custom CNN is created using Keras.\n",
    "The kernel Size (convolution window size), is chosen according to the publication that was given with the task."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, shape_states, hidden_layers_template, shape_actions):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.InputLayer(input_shape=shape_states)\n",
    "        self.hidden_layers = []\n",
    "        for hlt in hidden_layers_template:\n",
    "            self.hidden_layers.append(tf.keras.layers.Conv2D(\n",
    "                hlt, kernel_size=(3,3), activation='relu', kernel_initializer='RandomNormal'))\n",
    "        self.flatten_layer = tf.keras.layers.Flatten()\n",
    "        self.output_layer = tf.keras.layers.Dense(\n",
    "                shape_actions, activation='linear', kernel_initializer='RandomNormal')\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        z = self.input_layer(inputs)\n",
    "        for layer in self.hidden_layers:\n",
    "            z = layer(z)\n",
    "        flatten = self.flatten_layer(z)\n",
    "        output = self.output_layer(flatten)\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DQN class\n",
    "For easier creation of Target and Training model a custom class is created. It stores the hyperparameter gamma which represents the weight of future rewards."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class DeepQNetwork:\n",
    "    def __init__(self, shape_states, shape_actions, hidden_layers_template, gamma, max_number_experiences, min_number_experiences, batch_size, lr):\n",
    "        self.shape_actions = shape_actions\n",
    "        self.shape_states = shape_states\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = tf.optimizers.Adam(lr)\n",
    "        self.gamma = gamma\n",
    "        self.model = CustomModel(shape_states, hidden_layers_template, shape_actions)\n",
    "        self.experience = {'s': [], 'a': [], 'r': [], 's2': [], 'done': []}\n",
    "        self.max_number_experiences = max_number_experiences\n",
    "        self.min_number_experiences = min_number_experiences\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        if inputs.shape == self.shape_states:\n",
    "            inputs = np.expand_dims(inputs, axis = 0)\n",
    "        prediction = self.model(inputs.astype('float32'))\n",
    "        return prediction\n",
    "\n",
    "    def train(self, TargetNet):\n",
    "        if len(self.experience['s']) < self.min_experiences:\n",
    "            return 0\n",
    "        # chooses an random integer in range low to high, with batch_size samples\n",
    "        ids = np.random.randint(low=0, high=len(self.experience['s']), size=self.batch_size)\n",
    "        # sets states to an array of batch_size random experiences from the experience array\n",
    "        states = np.asarray([self.experience['s'][i] for i in ids])\n",
    "        # same for actions\n",
    "        actions = np.asarray([self.experience['a'][i] for i in ids])\n",
    "        # same for rewards\n",
    "        rewards = np.asarray([self.experience['r'][i] for i in ids])\n",
    "        # same for next states\n",
    "        states_next = np.asarray([self.experience['s2'][i] for i in ids])\n",
    "        # same for dones\n",
    "        dones = np.asarray([self.experience['done'][i] for i in ids])\n",
    "        # predicts the next values based on the next states\n",
    "        value_next = np.max(TargetNet.predict(states_next), axis=1)\n",
    "        # gets the reward where done is true \n",
    "        # and the reward + self.gamma * predicted_value) where done is false\n",
    "        actual_values = np.where(dones, rewards, rewards+self.gamma*value_next)\n",
    "        \n",
    "        with tf.GradientTape() as tensorflow_gradient_tape:\n",
    "            selected_action_values = tf.math.reduce_sum(\n",
    "                self.predict(states) * tf.one_hot(actions, self.shape_actions), axis=1)\n",
    "            loss = tf.math.reduce_mean(tf.square(actual_values - selected_action_values))\n",
    "        variables = self.model.trainable_variables\n",
    "        gradients = tensorflow_gradient_tape.gradient(loss, variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "        return loss\n",
    "\n",
    "    def get_action(self, states, epsilon):\n",
    "        if np.random.random() < epsilon:\n",
    "            return np.random.choice(self.shape_actions)\n",
    "        else:\n",
    "            return np.argmax(self.predict(states))\n",
    "\n",
    "    def add_experience(self, exp):\n",
    "        if len(self.experience['s']) >= self.max_number_experiences:\n",
    "            for key in self.experience.keys():\n",
    "                self.experience[key].pop(0)\n",
    "        for key, value in exp.items():\n",
    "            self.experience[key].append(value)\n",
    "\n",
    "    def copy_trainable_variables(self, network_to_copy_from):\n",
    "        own_trainable_vars = self.model.trainable_variables\n",
    "        other_trainable_vars = network_to_copy_from.model.trainable_variables\n",
    "        for vars1, vars2 in zip(own_trainable_vars, other_trainable_vars):\n",
    "            vars1.assign(vars2.numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def play_racing_kings(env, TrainNet, TargetNet, epsilon, copy_step):\n",
    "    rewards = 0\n",
    "    iter = 0\n",
    "    done = False\n",
    "    observations = env.reset()\n",
    "    losses = list()\n",
    "    while not done:\n",
    "        action = TrainNet.get_action(observations, epsilon)\n",
    "        prev_observations = observations\n",
    "        observations, reward, done, _ = env.step(action)\n",
    "        rewards += reward\n",
    "        if done:\n",
    "            env.reset()\n",
    "\n",
    "        exp = {'s': prev_observations, 'a': action, 'r': reward, 's2': observations, 'done': done}\n",
    "        TrainNet.add_experience(exp)\n",
    "        loss = TrainNet.train(TargetNet)\n",
    "        if isinstance(loss, int):\n",
    "            losses.append(loss)\n",
    "        else:\n",
    "            losses.append(loss.numpy())\n",
    "        iter += 1\n",
    "        if iter % copy_step == 0:\n",
    "            TargetNet.copy_trainable_variables(TrainNet)\n",
    "    return rewards, mean(losses), iter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "env = RacingKingsEnvironment()\n",
    "gamma = 0.99\n",
    "copy_step = 5\n",
    "hidden_units = [256, 256]\n",
    "max_experiences = 10000\n",
    "min_experiences = 100\n",
    "batch_size = 32\n",
    "lr = 1e-2\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'Training/Logs/CustomDQN-' + current_time + '-min_epsilon-025-decay-1e-5_no-neg-reward'\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "TrainNet = DeepQNetwork(env.state_shape, env.action_shape, hidden_units, gamma, max_experiences, min_experiences, batch_size, lr)\n",
    "TargetNet = DeepQNetwork(env.state_shape, env.action_shape, hidden_units, gamma, max_experiences, min_experiences, batch_size, lr)\n",
    "\n",
    "N = 100000\n",
    "StorageInterval = 500\n",
    "total_episode_rewards = np.empty(StorageInterval)\n",
    "total_episode_lengths = np.empty(StorageInterval)\n",
    "total_episode_losses = np.empty(StorageInterval)\n",
    "# starting epsilon: at the beginning of training 99 % of randomness are allowed\n",
    "epsilon = 0.99\n",
    "# sets the speed epsilon decreases to min epsilon\n",
    "decay = 1 - 1e-5\n",
    "# sets the end amount of randomness encounterd by to model on long term training to 1 %\n",
    "min_epsilon = 0.25\n",
    "for n in range(N):\n",
    "    epsilon = epsilon * decay\n",
    "    if epsilon < min_epsilon:\n",
    "        epsilon = min_epsilon\n",
    "    \n",
    "    reward, loss, step = play_racing_kings(env, TrainNet, TargetNet, epsilon, copy_step)\n",
    "    total_episode_rewards[n%StorageInterval] = reward\n",
    "    total_episode_lengths[n%StorageInterval] = step\n",
    "    total_episode_losses[n%StorageInterval] = loss\n",
    "    if n % StorageInterval == 0 and n != 0:\n",
    "        avg_episode_rewards = np.mean(total_episode_rewards)\n",
    "        avg_episode_length = np.mean(total_episode_lengths)\n",
    "        avg_episode_losses = np.mean(total_episode_losses)\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('mean_ep_length', avg_episode_length, step=n)\n",
    "            tf.summary.scalar('mean_reward', avg_episode_rewards, step=n)\n",
    "            tf.summary.scalar('loss', avg_episode_losses, step=n)\n",
    "            tf.summary.scalar('epsilon', epsilon, step=n)\n",
    "        print('episode:{} epsilon:{:.3} mean_reward:{:.3} mean_ep_length:{:.3} loss:{:.3}'\n",
    "                .format(n, float(epsilon), float(avg_episode_rewards), float(avg_episode_length), float(avg_episode_losses)))\n",
    "        total_episode_rewards = np.empty(StorageInterval)\n",
    "        total_episode_lengths = np.empty(StorageInterval)\n",
    "        total_episode_losses = np.empty(StorageInterval)\n",
    "env.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CustomModel.call at 0x7f482f119550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "episode:500 epsilon:0.985 mean_reward:0.0 mean_ep_length:1.02 loss:0.0226\n",
      "episode:1000 epsilon:0.98 mean_reward:0.0 mean_ep_length:1.01 loss:0.00404\n",
      "episode:1500 epsilon:0.975 mean_reward:0.0 mean_ep_length:1.01 loss:0.00795\n",
      "episode:2000 epsilon:0.97 mean_reward:0.0 mean_ep_length:1.01 loss:0.00654\n",
      "episode:2500 epsilon:0.966 mean_reward:0.0 mean_ep_length:1.02 loss:0.00747\n",
      "episode:3000 epsilon:0.961 mean_reward:0.0 mean_ep_length:1.02 loss:0.00835\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    # obs = env.reset()\n",
    "    env.board.reset()\n",
    "    obs, _, _, _ = env.step(None)\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render(mode=\"human\")\n",
    "        action = TrainNet.get_action(obs, 0)\n",
    "        print(\">>{}\".format(env.action_index_to_uci(action)))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{} Info:{}'.format(episode, score, info))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<b>Move 1 Black:</b><br/><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.2\" baseProfile=\"tiny\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><defs><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light lastmove g2\" stroke=\"none\" fill=\"#cdd16a\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark lastmove g5\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(15, 330)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(60, 330)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 330)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(150, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(285, 330)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(330, 330)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(15, 285)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(60, 285)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 285)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(150, 285)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(195, 285)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 285)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(330, 285)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(285, 150)\" /></svg>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>b1a1\n",
      "Episode:10 Score:0 Info:{'msg': 'Action is not a valid move'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save and Reload the Model Weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TrainNet.model.save_weights('Training/SavedModels/train_100k_net-025-1e-5_no-neg-reward.h5f', overwrite=True)\n",
    "TargetNet.model.save_weights('Training/SavedModels/target_100k_net-025-1e-5_no-neg-reward.h5f', overwrite=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Delete the current models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "del TrainNet.model\n",
    "del TargetNet.model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "load the model from memory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TrainNet.model = CustomModel(TrainNet.shape_states, [256, 256], TrainNet.shape_actions)\n",
    "TrainNet.model.load_weights('Training/SavedModels/train_100k_net-025-1e-5_no-neg-reward.h5f')\n",
    "TargetNet.model = CustomModel(TargetNet.shape_states, [256, 256], TargetNet.shape_actions)\n",
    "TargetNet.model.load_weights('Training/SavedModels/target_100k_net-025-1e-5_no-neg-reward.h5f')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f24a1d5bc10>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea16cf9687884ff056c50def91fea02e8f072861cbc27c56850047f3dd11ae6d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}